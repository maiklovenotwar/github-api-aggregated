# GitHub Data Analytics Pipeline

Ein hochperformantes ETL-System zur Analyse von GitHub-AktivitÃ¤tsdaten durch Integration von GitHub Archive und GitHub API.

## ğŸŒŸ Features

- Effiziente Verarbeitung von GitHub Archive Events
- Anreicherung mit GitHub API-Daten
- Parallele Batch-Verarbeitung
- Intelligentes Caching-System
- Performance-Monitoring und Visualisierung
- Robuste Fehlerbehandlung und Wiederaufnahme

## ğŸ— Projektstruktur

```
github-api/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ github_database/
â”‚       â”œâ”€â”€ api/                    # GitHub API Integration
â”‚       â”‚   â””â”€â”€ github_api.py       # API-Client und Rate-Limiting
â”‚       â”‚
â”‚       â”œâ”€â”€ database/              # Datenbankmodelle und Verwaltung
â”‚       â”‚   â”œâ”€â”€ database.py        # SQLAlchemy-Modelle und Datenbankinitialisierung
â”‚       â”‚   â””â”€â”€ migrations/        # Alembic Migrationsskripte
â”‚       â”‚
â”‚       â”œâ”€â”€ enrichment/            # Datenanreicherung
â”‚       â”‚   â””â”€â”€ data_enricher.py   # Anreicherung mit API-Daten
â”‚       â”‚
â”‚       â”œâ”€â”€ github_archive/        # GitHub Archive Verarbeitung
â”‚       â”‚   â””â”€â”€ github_archive.py  # Download und Parsing von Archivdaten
â”‚       â”‚
â”‚       â”œâ”€â”€ mapping/              # Event-Mapping
â”‚       â”‚   â””â”€â”€ repository_mapper.py # Mapping von Events zu Datenbankmodellen
â”‚       â”‚
â”‚       â”œâ”€â”€ monitoring/           # Performance-Ãœberwachung
â”‚       â”‚   â””â”€â”€ performance_monitor.py # Metriken und Visualisierung
â”‚       â”‚
â”‚       â”œâ”€â”€ processing/           # Datenverarbeitung
â”‚       â”‚   â””â”€â”€ batch_processor.py # Effiziente Batch-Verarbeitung
â”‚       â”‚
â”‚       â”œâ”€â”€ config.py            # Konfigurationsverwaltung
â”‚       â”œâ”€â”€ etl_orchestrator.py  # ETL-Prozesssteuerung
â”‚       â””â”€â”€ main.py             # Hauptanwendung
â”‚
â”œâ”€â”€ tests/                      # Unittest-Suite
â”œâ”€â”€ requirements.txt           # Python-AbhÃ¤ngigkeiten
â””â”€â”€ README.md                 # Projektdokumentation
```

## ğŸ”‘ Hauptkomponenten

### ETL Orchestrator
- **Datei**: `etl_orchestrator.py`
- **Funktion**: Zentrale Steuerung des ETL-Prozesses
- **Features**:
  - Streaming-Verarbeitung von Archivdaten
  - Automatische Batch-GrÃ¶ÃŸenoptimierung
  - Fortschrittsverfolgung
  - Fehlerbehandlung und Wiederaufnahme

### Batch Processor
- **Datei**: `processing/batch_processor.py`
- **Funktion**: Effiziente Batch-Verarbeitung von Events
- **Features**:
  - Multi-Threading
  - Optimierte SQLAlchemy-Operationen
  - Event-Typ-basierte Queues
  - Automatische Ressourcenanpassung

### Data Enricher
- **Datei**: `enrichment/data_enricher.py`
- **Funktion**: Anreicherung von Daten mit GitHub API
- **Features**:
  - Mehrstufiges Caching (Memory + Disk)
  - Rate-Limiting-Verwaltung
  - Batch-Anreicherung
  - Fehlertoleranz

### Repository Mapper
- **Datei**: `mapping/repository_mapper.py`
- **Funktion**: Mapping von Events zu Datenbankmodellen
- **Features**:
  - Validierung von Event-Daten
  - Effiziente Objekterstellung
  - Caching hÃ¤ufig verwendeter Objekte
  - Thread-sichere Implementierung

### Performance Monitor
- **Datei**: `monitoring/performance_monitor.py`
- **Funktion**: Ãœberwachung und Visualisierung der Performance
- **Features**:
  - Echtzeit-Metriken
  - Grafische Dashboards
  - RessourcenÃ¼berwachung
  - Metrik-Persistenz

## ğŸš€ Verwendung

### Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/github-api.git
cd github-api

# Virtuelle Umgebung erstellen und aktivieren
python -m venv venv
source venv/bin/activate  # Unix
venv\Scripts\activate     # Windows

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt
```

### Konfiguration

```python
from github_database.config import ETLConfig

config = ETLConfig(
    api_token="your_github_token",
    database_url="sqlite:///github_data.db",
    batch_size=1000
)
```

### Datenverarbeitung starten

```python
from github_database.etl_orchestrator import ETLOrchestrator
from datetime import datetime, timedelta

# ETL-Prozess initialisieren
orchestrator = ETLOrchestrator(config)

# Zeitraum festlegen
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 1, 7)

# Verarbeitung starten
orchestrator.process_archive(start_date, end_date)
```

## ğŸ“Š Performance-Optimierung

Das System enthÃ¤lt mehrere Optimierungen fÃ¼r hohe Performance:

1. **Batch-Verarbeitung**:
   - Automatische Batch-GrÃ¶ÃŸenanpassung
   - Effiziente Bulk-Operationen
   - Event-Typ-basiertes Batching

2. **Parallelisierung**:
   - Thread-Pool fÃ¼r gleichzeitige Verarbeitung
   - Thread-sichere Datenbankzugriffe
   - Optimierte Worker-Anzahl

3. **Caching**:
   - Mehrstufiges Caching-System
   - LRU-basierte Cache-Eviction
   - Persistenter Disk-Cache

4. **Datenbankoptimierung**:
   - Strategische Indizierung
   - Connection-Pooling
   - Effiziente Abfragemuster

5. **Speichermanagement**:
   - Streaming groÃŸer Dateien
   - Automatische Garbage-Collection
   - Speichereffiziente Datenstrukturen

## ğŸ“ˆ Monitoring

Das integrierte Monitoring-System bietet:

- Echtzeit-Performance-Metriken
- Grafische Dashboards
- CPU- und SpeicherÃ¼berwachung
- Durchsatz- und Fehlerstatistiken

## ğŸ›  Tests

```bash
# Alle Tests ausfÃ¼hren
python -m pytest tests/

# Spezifische Test-Suite ausfÃ¼hren
python -m pytest tests/test_batch_processor.py
```

## ğŸ“ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.