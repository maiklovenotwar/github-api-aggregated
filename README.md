# GitHub Data Analytics Pipeline

Ein hochperformantes ETL-System zur Analyse von GitHub-AktivitÃ¤tsdaten durch hybride Integration von GitHub API und BigQuery.

## ğŸŒŸ Features

- Hybride Datenerfassung (GitHub API + BigQuery)
- Effiziente Verarbeitung von GitHub Archive Events via BigQuery
- Anreicherung mit GitHub API-Metadaten
- Parallele Batch-Verarbeitung
- Intelligentes Caching-System
- Performance-Monitoring und Visualisierung
- Robuste Fehlerbehandlung und Wiederaufnahme

## ğŸ— Projektstruktur

```
github-api/
â”œâ”€â”€ src/
â”‚   â””â”€â”€ github_database/
â”‚       â”œâ”€â”€ api/                    # GitHub API Integration
â”‚       â”‚   â”œâ”€â”€ github_api.py       # API-Client und Rate-Limiting
â”‚       â”‚   â””â”€â”€ bigquery_api.py     # BigQuery-Client fÃ¼r GitHub Archive
â”‚       â”‚
â”‚       â”œâ”€â”€ analysis/               # Datenanalyse-Komponenten
â”‚       â”‚   â”œâ”€â”€ location_analysis.py # Standortbasierte Analyse
â”‚       â”‚   â””â”€â”€ organization_analysis.py # Organisationsanalyse
â”‚       â”‚
â”‚       â”œâ”€â”€ control_database/       # Datenbankvalidierung und -kontrolle
â”‚       â”‚   â””â”€â”€ validate_data.py    # Datenvalidierungsfunktionen
â”‚       â”‚
â”‚       â”œâ”€â”€ database/               # Datenbankmodelle und Verwaltung
â”‚       â”‚   â”œâ”€â”€ database.py         # SQLAlchemy-Modelle
â”‚       â”‚   â””â”€â”€ migrations/         # Alembic Migrationsskripte
â”‚       â”‚
â”‚       â”œâ”€â”€ enrichment/             # Datenanreicherung
â”‚       â”‚   â””â”€â”€ data_enricher.py    # Anreicherung mit API-Daten
â”‚       â”‚
â”‚       â”œâ”€â”€ config/                 # Konfiguration
â”‚       â”‚   â”œâ”€â”€ config.py           # Hauptkonfiguration
â”‚       â”‚   â””â”€â”€ bigquery_config.py  # BigQuery-spezifische Konfiguration
â”‚       â”‚
â”‚       â”œâ”€â”€ monitoring/             # Performance-Ãœberwachung
â”‚       â”‚   â””â”€â”€ performance_monitor.py # Metriken und Visualisierung
â”‚       â”‚
â”‚       â”œâ”€â”€ github_archive.py       # GitHub Archive Event-Typen
â”‚       â”œâ”€â”€ etl_orchestrator.py     # Hybride ETL-Prozesssteuerung
â”‚       â””â”€â”€ main.py                 # Hauptanwendung
â”‚
â”œâ”€â”€ docs/                           # Dokumentation
â”‚   â”œâ”€â”€ ARCHITECTURE.md             # Systemarchitektur
â”‚   â”œâ”€â”€ BIGQUERY_SETUP.md           # BigQuery-Einrichtung
â”‚   â””â”€â”€ USAGE.md                    # Nutzungsanleitungen
â”‚
â”œâ”€â”€ tests/                          # Testsuite
â”‚   â”œâ”€â”€ test_hybrid_pipeline.py     # Tests fÃ¼r hybride Pipeline
â”‚   â””â”€â”€ analyze_test_results.py     # Testanalyse und Visualisierung
â”‚
â”œâ”€â”€ .env.template                  # Umgebungsvariablen-Template
â”œâ”€â”€ requirements.txt               # Python-AbhÃ¤ngigkeiten
â””â”€â”€ README.md                      # Projektdokumentation
```

## ğŸ”‘ Hauptkomponenten

### Hybride ETL-Pipeline
- **Datei**: `etl_orchestrator.py`
- **Funktion**: Orchestrierung der hybriden Datenerfassung
- **Features**:
  - Parallele Verarbeitung von API- und BigQuery-Daten
  - Intelligente Lastverteilung
  - Automatische Fehlerbehandlung
  - Fortschrittsverfolgung

### BigQuery Integration
- **Datei**: `bigquery/bigquery_client.py`
- **Funktion**: Effiziente Abfrage historischer GitHub-Daten
- **Features**:
  - Optimierte SQL-Queries
  - Kostenkontrolle
  - Streaming-Verarbeitung
  - Automatische Retry-Logik

### GitHub API Client
- **Datei**: `api/github_api.py`
- **Funktion**: Metadaten-Erfassung und Anreicherung
- **Features**:
  - Rate-Limiting-Management
  - Caching-System
  - Parallele Anfragen
  - Fehlertoleranz

## ğŸš€ Schnellstart

### 1. Installation

```bash
# Repository klonen
git clone https://github.com/yourusername/github-api.git
cd github-api

# Virtuelle Umgebung erstellen und aktivieren
python -m venv venv
source venv/bin/activate  # Unix
venv\Scripts\activate     # Windows

# AbhÃ¤ngigkeiten installieren
pip install -r requirements.txt
```

### 2. Google Cloud Setup

Folgen Sie der Anleitung in `docs/BIGQUERY_SETUP.md` fÃ¼r:
- Google Cloud Projekt-Einrichtung
- Service Account-Erstellung
- BigQuery API-Aktivierung
- Credentials-Konfiguration

### 3. Konfiguration

1. Umgebungsvariablen einrichten:
```bash
cp .env.template .env
# .env bearbeiten und Werte einfÃ¼gen
```

2. Python-Konfiguration:
```python
from github_database.config import ETLConfig
from github_database.config.bigquery_config import BigQueryConfig

# BigQuery-Konfiguration
bigquery_config = BigQueryConfig(
    project_id="your-project-id",
    dataset_id="githubarchive",
    credentials_path="/path/to/credentials.json"
)

# ETL-Konfiguration
config = ETLConfig(
    api_token="your_github_token",
    database_url="sqlite:///github_data.db",
    bigquery_config=bigquery_config
)
```

### 4. Datenverarbeitung starten

```python
from github_database.etl_orchestrator import ETLOrchestrator
from datetime import datetime, timedelta

# ETL-Prozess initialisieren
orchestrator = ETLOrchestrator(config)

# Zeitraum festlegen
start_date = datetime(2024, 1, 1)
end_date = datetime(2024, 1, 7)

# Verarbeitung starten
orchestrator.process_repositories(
    start_date=start_date,
    end_date=end_date,
    min_stars=50,  # QualitÃ¤tsfilter
    min_forks=10
)
```

## ğŸ’¡ Vorteile des hybriden Ansatzes

1. **Effiziente Datenerfassung**:
   - Historische Daten via BigQuery
   - Aktuelle Metadaten via GitHub API
   - Optimale Ressourcennutzung

2. **Kostenoptimierung**:
   - Reduzierte API-Aufrufe
   - Effiziente BigQuery-Nutzung
   - Intelligentes Caching

3. **Verbesserte DatenqualitÃ¤t**:
   - Kreuzvalidierung von Datenquellen
   - Umfassendere DatensÃ¤tze
   - Aktuelle Metadaten

4. **Hohe Performance**:
   - Parallele Verarbeitung
   - Optimierte Queries
   - Effizientes Ressourcenmanagement

## ğŸ“Š Performance-Monitoring

Das integrierte Monitoring-System bietet:

- Echtzeit-Performance-Metriken
- BigQuery-KostenÃ¼berwachung
- API-Rate-Limiting-Statistiken
- Ressourcenauslastung

## ğŸ“‹ Status der Module

### Aktiv verwendete Kernmodule
- **main.py**: Haupteinstiegspunkt der Anwendung
- **etl_orchestrator.py**: Kernkomponente fÃ¼r die ETL-Prozesse
- **api/github_api.py** und **api/bigquery_api.py**: API-Clients fÃ¼r GitHub und BigQuery
- **database/database.py**: Datenbankmodelle und Initialisierung
- **config/**: Konfigurationsmodule fÃ¼r die Anwendung

### Module fÃ¼r zukÃ¼nftige Erweiterungen
Folgende Module sind fÃ¼r zukÃ¼nftige FunktionalitÃ¤ten vorgesehen und werden derzeit nicht aktiv in der Hauptanwendung verwendet:

1. **Analyse-Module** (`analysis/`):
   - `location_analysis.py`: Standortbasierte Analyse von Repositories und Nutzern
   - `organization_analysis.py`: Analyse von OrganisationsaktivitÃ¤ten
   - `visualization.py`: Visualisierungskomponenten fÃ¼r Analyseergebnisse

2. **Datenbank-Kontrollmodule** (`control_database/`):
   - `cleanup_duplicates.py`: Bereinigung von Duplikaten in der Datenbank
   - `control_data.py`: Kontrollfunktionen fÃ¼r Datenbankoperationen
   - `validate_data.py`: Validierung von Daten vor dem Import

3. **Datenanreicherung und Mapping** (`enrichment/`, `mapping/`):
   - `data_enricher.py`: Anreicherung von GitHub-Daten mit zusÃ¤tzlichen Informationen
   - `repository_mapper.py`: Mapping von GitHub-Archive-Events auf Datenbankmodelle

4. **Monitoring und Batch-Verarbeitung** (`monitoring/`, `processing/`):
   - `performance_monitor.py`: Ãœberwachung der Anwendungsleistung
   - `batch_processor.py`: Effiziente Batch-Verarbeitung fÃ¼r Datenbankoperationen

Diese Module bieten eine solide Grundlage fÃ¼r zukÃ¼nftige Erweiterungen des Systems und kÃ¶nnen je nach Bedarf aktiviert und in die Hauptanwendung integriert werden.

## ğŸ§ª Tests

```bash
# Hybrid Pipeline testen
python -m tests.test_hybrid_pipeline

# Testergebnisse analysieren
python -m tests.analyze_test_results
```

## ğŸ“š WeiterfÃ¼hrende Dokumentation

- [Systemarchitektur](docs/ARCHITECTURE.md)
- [BigQuery Setup](docs/BIGQUERY_SETUP.md)
- [Nutzungsanleitungen](docs/USAGE.md)

## ğŸ“ Lizenz

Dieses Projekt ist unter der MIT-Lizenz lizenziert - siehe die [LICENSE](LICENSE) Datei fÃ¼r Details.